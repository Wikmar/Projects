{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting House Sale Prices\n",
    "This project delves into linear regression and how to improve it by data cleaning and using cross validation in order to reduce RMSE. We work with a dataset containing housing data from Ames, Iowa, United States from 2006 to 2010 and seek to predict the Sale Price of houses.  \n",
    "We'll initially import some libraries into our environment and predefine functions we'll later build upon. We'll start with just a simple linear regression model on the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57088.25161263909"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "data = pd.read_csv('datasets/AmesHousing.tsv', delimiter='\\t')\n",
    "\n",
    "def transform_features(df):\n",
    "    return df\n",
    "\n",
    "def select_features(df):\n",
    "    return df[['Gr Liv Area', 'SalePrice']]\n",
    "\n",
    "def train_and_test(df):\n",
    "    train = df[:1460].select_dtypes(include=['integer', 'float'])\n",
    "    test = df[1460:].select_dtypes(include=['integer', 'float'])\n",
    "    features = train.columns.drop('SalePrice')\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(train[features],train['SalePrice'])\n",
    "    predict = lr.predict(test[features])\n",
    "    mse = mean_squared_error(predict, test['SalePrice'])\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "transform_df = transform_features(data)\n",
    "filtered_df = select_features(transform_df)\n",
    "rmse = train_and_test(filtered_df)\n",
    "\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "We'll proceed to start cleaning up the data by:\n",
    "1. Removing columns containing more than 5% missing values\n",
    "2. Dropping columns that are text based that contain any missing values\n",
    "3. Fill missing values in numerical columns with the most common value of the entire column  \n",
    "  \n",
    "Note that these changes can be reverted if we deem missing columns usefull/necessary to carry out a satisfactory regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2930 entries, 0 to 2929\n",
      "Data columns (total 82 columns):\n",
      "Order              2930 non-null int64\n",
      "PID                2930 non-null int64\n",
      "MS SubClass        2930 non-null int64\n",
      "MS Zoning          2930 non-null object\n",
      "Lot Frontage       2440 non-null float64\n",
      "Lot Area           2930 non-null int64\n",
      "Street             2930 non-null object\n",
      "Alley              198 non-null object\n",
      "Lot Shape          2930 non-null object\n",
      "Land Contour       2930 non-null object\n",
      "Utilities          2930 non-null object\n",
      "Lot Config         2930 non-null object\n",
      "Land Slope         2930 non-null object\n",
      "Neighborhood       2930 non-null object\n",
      "Condition 1        2930 non-null object\n",
      "Condition 2        2930 non-null object\n",
      "Bldg Type          2930 non-null object\n",
      "House Style        2930 non-null object\n",
      "Overall Qual       2930 non-null int64\n",
      "Overall Cond       2930 non-null int64\n",
      "Year Built         2930 non-null int64\n",
      "Year Remod/Add     2930 non-null int64\n",
      "Roof Style         2930 non-null object\n",
      "Roof Matl          2930 non-null object\n",
      "Exterior 1st       2930 non-null object\n",
      "Exterior 2nd       2930 non-null object\n",
      "Mas Vnr Type       2907 non-null object\n",
      "Mas Vnr Area       2907 non-null float64\n",
      "Exter Qual         2930 non-null object\n",
      "Exter Cond         2930 non-null object\n",
      "Foundation         2930 non-null object\n",
      "Bsmt Qual          2850 non-null object\n",
      "Bsmt Cond          2850 non-null object\n",
      "Bsmt Exposure      2847 non-null object\n",
      "BsmtFin Type 1     2850 non-null object\n",
      "BsmtFin SF 1       2929 non-null float64\n",
      "BsmtFin Type 2     2849 non-null object\n",
      "BsmtFin SF 2       2929 non-null float64\n",
      "Bsmt Unf SF        2929 non-null float64\n",
      "Total Bsmt SF      2929 non-null float64\n",
      "Heating            2930 non-null object\n",
      "Heating QC         2930 non-null object\n",
      "Central Air        2930 non-null object\n",
      "Electrical         2929 non-null object\n",
      "1st Flr SF         2930 non-null int64\n",
      "2nd Flr SF         2930 non-null int64\n",
      "Low Qual Fin SF    2930 non-null int64\n",
      "Gr Liv Area        2930 non-null int64\n",
      "Bsmt Full Bath     2928 non-null float64\n",
      "Bsmt Half Bath     2928 non-null float64\n",
      "Full Bath          2930 non-null int64\n",
      "Half Bath          2930 non-null int64\n",
      "Bedroom AbvGr      2930 non-null int64\n",
      "Kitchen AbvGr      2930 non-null int64\n",
      "Kitchen Qual       2930 non-null object\n",
      "TotRms AbvGrd      2930 non-null int64\n",
      "Functional         2930 non-null object\n",
      "Fireplaces         2930 non-null int64\n",
      "Fireplace Qu       1508 non-null object\n",
      "Garage Type        2773 non-null object\n",
      "Garage Yr Blt      2771 non-null float64\n",
      "Garage Finish      2771 non-null object\n",
      "Garage Cars        2929 non-null float64\n",
      "Garage Area        2929 non-null float64\n",
      "Garage Qual        2771 non-null object\n",
      "Garage Cond        2771 non-null object\n",
      "Paved Drive        2930 non-null object\n",
      "Wood Deck SF       2930 non-null int64\n",
      "Open Porch SF      2930 non-null int64\n",
      "Enclosed Porch     2930 non-null int64\n",
      "3Ssn Porch         2930 non-null int64\n",
      "Screen Porch       2930 non-null int64\n",
      "Pool Area          2930 non-null int64\n",
      "Pool QC            13 non-null object\n",
      "Fence              572 non-null object\n",
      "Misc Feature       106 non-null object\n",
      "Misc Val           2930 non-null int64\n",
      "Mo Sold            2930 non-null int64\n",
      "Yr Sold            2930 non-null int64\n",
      "Sale Type          2930 non-null object\n",
      "Sale Condition     2930 non-null object\n",
      "SalePrice          2930 non-null int64\n",
      "dtypes: float64(11), int64(28), object(43)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting any column containing more than 5% missing entries\n",
    "\n",
    "missing = data.isnull().sum()\n",
    "to_drop_missing = missing[(missing > len(data)/20)].sort_values()\n",
    "data = data.drop(to_drop_missing.index, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping text columns with 1 or more missing entries\n",
    "\n",
    "text_missing_counts = data.select_dtypes(include=['object']).isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "data = data.drop(text_missing_counts[(text_missing_counts > 0)].index, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BsmtFin SF 1': 0.0,\n",
       " 'BsmtFin SF 2': 0.0,\n",
       " 'Bsmt Unf SF': 0.0,\n",
       " 'Total Bsmt SF': 0.0,\n",
       " 'Garage Cars': 2.0,\n",
       " 'Garage Area': 0.0,\n",
       " 'Bsmt Full Bath': 0.0,\n",
       " 'Bsmt Half Bath': 0.0,\n",
       " 'Mas Vnr Area': 0.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filling missing numerical column values with the most common value of it's respective column\n",
    "\n",
    "missing = data.select_dtypes(include=['int', 'float']).isnull().sum()\n",
    "missing = missing[(missing > 0)].sort_values()\n",
    "vals_to_replace = data[missing.index].mode().to_dict(orient='records')[0]\n",
    "vals_to_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    64\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.fillna(vals_to_replace)\n",
    "data.isnull().sum().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing the Year Built and Year Sold we can make a new feature describing the amount of time it took from being built to being sold, which will make our analysis easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2180   -1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years_sold = data['Yr Sold'] - data['Year Built']\n",
    "years_sold[years_sold < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly we can do the same with houses remodelled and the time it took to sell afterwards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1702   -1\n",
       "2180   -2\n",
       "2181   -1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years_remod = data['Yr Sold'] - data['Year Remod/Add']\n",
    "years_remod[years_remod < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new features to the dataset and delete rows with negative values\n",
    "data['Years Before Sale'] = years_sold\n",
    "data['Years After Remod'] = years_remod\n",
    "\n",
    "data = data.drop([1702,2180,2181], axis=0)\n",
    "\n",
    "data = data.drop(['Yr Sold','Year Remod/Add'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now drop columns that we feel are not useful for machine learning, or leak data about the final sale of the house:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not useful for ML\n",
    "data = data.drop(['PID', 'Order'], axis=1)\n",
    "\n",
    "## Leak info of final sale\n",
    "data = data.drop(['Mo Sold', 'Sale Condition', 'Sale Type'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's update transform_features() with this code we've developed and see if the RMSE has decreased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55275.367312413066"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_features(data):\n",
    "    missing = data.isnull().sum()\n",
    "    to_drop_missing = missing[(missing > len(data)/20)].sort_values()\n",
    "    data = data.drop(to_drop_missing.index, axis=1)\n",
    "    \n",
    "    text_missing_counts = data.select_dtypes(include=['object']).isnull().sum().sort_values(ascending=False)\n",
    "    data = data.drop(text_missing_counts[(text_missing_counts > 0)].index, axis=1)\n",
    "    \n",
    "    missing = data.select_dtypes(include=['int', 'float']).isnull().sum()\n",
    "    missing = missing[(missing > 0)].sort_values()\n",
    "    vals_to_replace = data[missing.index].mode().to_dict(orient='records')[0]\n",
    "    data = data.fillna(vals_to_replace)\n",
    "    \n",
    "    years_sold = data['Yr Sold'] - data['Year Built']\n",
    "    years_remod = data['Yr Sold'] - data['Year Remod/Add']\n",
    "    data['Years Before Sale'] = years_sold\n",
    "    data['Years After Remod'] = years_remod\n",
    "    \n",
    "    data = data.drop([1702,2180,2181], axis=0)\n",
    "    data = data.drop(['Mo Sold', 'Sale Condition', 'Sale Type','PID', 'Order','Yr Sold','Year Remod/Add','Yr Sold'], axis=1)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def select_features(df):\n",
    "    return df[['Gr Liv Area', 'SalePrice']]\n",
    "\n",
    "def train_and_test(df):\n",
    "    train = df[:1460].select_dtypes(include=['integer', 'float'])\n",
    "    test = df[1460:].select_dtypes(include=['integer', 'float'])\n",
    "    features = train.columns.drop('SalePrice')\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(train[features],train['SalePrice'])\n",
    "    predict = lr.predict(test[features])\n",
    "    mse = mean_squared_error(predict, test['SalePrice'])\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "data = pd.read_csv(\"datasets/AmesHousing.tsv\", delimiter=\"\\t\")\n",
    "transform_df = transform_features(data)\n",
    "filtered_df = select_features(transform_df)\n",
    "rmse = train_and_test(filtered_df)\n",
    "\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BsmtFin SF 2         0.006127\n",
       "Misc Val             0.019273\n",
       "3Ssn Porch           0.032268\n",
       "Bsmt Half Bath       0.035875\n",
       "Low Qual Fin SF      0.037629\n",
       "Pool Area            0.068438\n",
       "MS SubClass          0.085128\n",
       "Overall Cond         0.101540\n",
       "Screen Porch         0.112280\n",
       "Kitchen AbvGr        0.119760\n",
       "Enclosed Porch       0.128685\n",
       "Bedroom AbvGr        0.143916\n",
       "Bsmt Unf SF          0.182751\n",
       "Lot Area             0.267520\n",
       "2nd Flr SF           0.269601\n",
       "Bsmt Full Bath       0.276258\n",
       "Half Bath            0.284871\n",
       "Open Porch SF        0.316262\n",
       "Wood Deck SF         0.328183\n",
       "BsmtFin SF 1         0.439284\n",
       "Fireplaces           0.474831\n",
       "TotRms AbvGrd        0.498574\n",
       "Mas Vnr Area         0.506983\n",
       "Years After Remod    0.534985\n",
       "Full Bath            0.546118\n",
       "Year Built           0.558490\n",
       "Years Before Sale    0.558979\n",
       "1st Flr SF           0.635185\n",
       "Garage Area          0.641425\n",
       "Total Bsmt SF        0.644012\n",
       "Garage Cars          0.648361\n",
       "Gr Liv Area          0.717596\n",
       "Overall Qual         0.801206\n",
       "SalePrice            1.000000\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "num_data = transform_df.select_dtypes(include=['int', 'float'])\n",
    "\n",
    "corr_coeffs = num_data.corr()['SalePrice'].abs().sort_values()\n",
    "corr_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BsmtFin SF 1         0.439284\n",
       "Fireplaces           0.474831\n",
       "TotRms AbvGrd        0.498574\n",
       "Mas Vnr Area         0.506983\n",
       "Years After Remod    0.534985\n",
       "Full Bath            0.546118\n",
       "Year Built           0.558490\n",
       "Years Before Sale    0.558979\n",
       "1st Flr SF           0.635185\n",
       "Garage Area          0.641425\n",
       "Total Bsmt SF        0.644012\n",
       "Garage Cars          0.648361\n",
       "Gr Liv Area          0.717596\n",
       "Overall Qual         0.801206\n",
       "SalePrice            1.000000\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_coeffs = corr_coeffs[corr_coeffs > 0.35]\n",
    "corr_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop columns with less than 0.35 correlation with SalePrice\n",
    "transform_df = transform_df.drop(corr_coeffs[corr_coeffs < 0.35].index, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define all nominal features that should be categorical. For each column depending on its' type:\n",
    "* If numerical we'll encode them to be categorical, as numbers do not have any semantic meaning to them\n",
    "* If there are too many numerical values we'll remove it from the dataset, as adding dummy columns back will be labourious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MS SubClass',\n",
       " 'MS Zoning',\n",
       " 'Street',\n",
       " 'Land Contour',\n",
       " 'Lot Config',\n",
       " 'Neighborhood',\n",
       " 'Condition 1',\n",
       " 'Condition 2',\n",
       " 'Bldg Type',\n",
       " 'House Style',\n",
       " 'Roof Style',\n",
       " 'Roof Matl',\n",
       " 'Exterior 1st',\n",
       " 'Exterior 2nd',\n",
       " 'Foundation',\n",
       " 'Heating',\n",
       " 'Central Air']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nominal_features = [\"PID\", \"MS SubClass\", \"MS Zoning\", \"Street\", \"Alley\", \"Land Contour\", \"Lot Config\", \"Neighborhood\", \n",
    "                    \"Condition 1\", \"Condition 2\", \"Bldg Type\", \"House Style\", \"Roof Style\", \"Roof Matl\", \"Exterior 1st\", \n",
    "                    \"Exterior 2nd\", \"Mas Vnr Type\", \"Foundation\", \"Heating\", \"Central Air\", \"Garage Type\", \n",
    "                    \"Misc Feature\", \"Sale Type\", \"Sale Condition\"]\n",
    "\n",
    "# Features that are still in our dataframe \n",
    "\n",
    "nom_cols = []\n",
    "for col in nominal_features:\n",
    "    if col in transform_df.columns:\n",
    "        nom_cols.append(col)\n",
    "        \n",
    "nom_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique values in these columns\n",
    "unique_counts = transform_df[nom_cols].apply(lambda x: len(x.value_counts())).sort_values()\n",
    "\n",
    "# Cutoff any columns that have more than 10 unique values\n",
    "drop_cols = unique_counts[unique_counts > 10].index\n",
    "transform_df = transform_df.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting text columns to categorical\n",
    "text_cols = transform_df.select_dtypes(include=['object'])\n",
    "for col in text_cols:\n",
    "    transform_df[col] = transform_df[col].astype('category')\n",
    "\n",
    "# Dummy columns, then add back to the dataframe\n",
    "transform_df = pd.concat([\n",
    "    transform_df, pd.get_dummies(transform_df.select_dtypes(include=['category']))]\n",
    "    , axis=1).drop(text_cols,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll again update our functions and also add a k parameter that controls any cross validation that occurs making use of the KFold function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26566.04026918346, 36903.06301303401, 25246.865533336502, 25307.93446822479]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28505.975820944688"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def transform_features(data):\n",
    "    missing = data.isnull().sum()\n",
    "    to_drop_missing = missing[(missing > len(data)/20)].sort_values()\n",
    "    data = data.drop(to_drop_missing.index, axis=1)\n",
    "    \n",
    "    text_missing_counts = data.select_dtypes(include=['object']).isnull().sum().sort_values(ascending=False)\n",
    "    data = data.drop(text_missing_counts[(text_missing_counts > 0)].index, axis=1)\n",
    "    \n",
    "    missing = data.select_dtypes(include=['int', 'float']).isnull().sum()\n",
    "    missing = missing[(missing > 0)].sort_values()\n",
    "    vals_to_replace = data[missing.index].mode().to_dict(orient='records')[0]\n",
    "    data = data.fillna(vals_to_replace)\n",
    "    \n",
    "    years_sold = data['Yr Sold'] - data['Year Built']\n",
    "    years_remod = data['Yr Sold'] - data['Year Remod/Add']\n",
    "    data['Years Before Sale'] = years_sold\n",
    "    data['Years After Remod'] = years_remod\n",
    "    \n",
    "    data = data.drop([1702,2180,2181], axis=0)\n",
    "    data = data.drop(['Mo Sold', 'Sale Condition', 'Sale Type','PID', 'Order','Yr Sold','Year Remod/Add','Yr Sold'], axis=1)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def select_features(df):\n",
    "    num_data = df.select_dtypes(include=['int', 'float'])\n",
    "    corr_coeffs = num_data.corr()['SalePrice'].abs().sort_values()\n",
    "    df = df.drop(corr_coeffs[corr_coeffs < 0.35].index, axis=1)\n",
    "\n",
    "    nom_cols = []\n",
    "    for col in nominal_features:\n",
    "        if col in df.columns:\n",
    "            nom_cols.append(col)\n",
    "        \n",
    "    unique_counts = df[nom_cols].apply(lambda x: len(x.value_counts())).sort_values()\n",
    "    drop_cols = unique_counts[unique_counts > 10].index\n",
    "    df = df.drop(drop_cols, axis=1)\n",
    "    \n",
    "    text_cols = df.select_dtypes(include=['object'])\n",
    "    for col in text_cols:\n",
    "        df[col] = df[col].astype('category')\n",
    "\n",
    "    df = pd.concat([\n",
    "    df, pd.get_dummies(df.select_dtypes(include=['category']))]\n",
    "    , axis=1).drop(text_cols,axis=1)\n",
    "    \n",
    "    return df[['Gr Liv Area', 'SalePrice']]\n",
    "\n",
    "def train_and_test(df, k):\n",
    "    lr = LinearRegression()\n",
    "    features = df.columns.drop('SalePrice')\n",
    "    num_df = df.select_dtypes(include=['integer', 'float'])\n",
    "    \n",
    "    if k ==0:\n",
    "        train = df[:1460]\n",
    "        test = df[1460:]\n",
    "        lr.fit(train[features],train['SalePrice'])\n",
    "        predict = lr.predict(test[features])\n",
    "        mse = mean_squared_error(predict, test['SalePrice'])\n",
    "        rmse = np.sqrt(mse)\n",
    "    \n",
    "        return rmse\n",
    "\n",
    "    \n",
    "def transform_features(df):\n",
    "    num_missing = df.isnull().sum()\n",
    "    drop_missing_cols = num_missing[(num_missing > len(df)/20)].sort_values()\n",
    "    df = df.drop(drop_missing_cols.index, axis=1)\n",
    "    \n",
    "    text_mv_counts = df.select_dtypes(include=['object']).isnull().sum().sort_values(ascending=False)\n",
    "    drop_missing_cols_2 = text_mv_counts[text_mv_counts > 0]\n",
    "    df = df.drop(drop_missing_cols_2.index, axis=1)\n",
    "    \n",
    "    num_missing = df.select_dtypes(include=['int', 'float']).isnull().sum()\n",
    "    fixable_numeric_cols = num_missing[(num_missing < len(df)/20) & (num_missing > 0)].sort_values()\n",
    "    replacement_values_dict = df[fixable_numeric_cols.index].mode().to_dict(orient='records')[0]\n",
    "    df = df.fillna(replacement_values_dict)\n",
    "    \n",
    "    years_sold = df['Yr Sold'] - df['Year Built']\n",
    "    years_since_remod = df['Yr Sold'] - df['Year Remod/Add']\n",
    "    df['Years Before Sale'] = years_sold\n",
    "    df['Years Since Remod'] = years_since_remod\n",
    "    df = df.drop([1702, 2180, 2181], axis=0)\n",
    "\n",
    "    df = df.drop([\"PID\", \"Order\", \"Mo Sold\", \"Sale Condition\", \"Sale Type\", \"Year Built\", \"Year Remod/Add\"], axis=1)\n",
    "    return df\n",
    "\n",
    "def select_features(df, coeff_threshold=0.4, uniq_threshold=10):\n",
    "    numerical_df = df.select_dtypes(include=['int', 'float'])\n",
    "    abs_corr_coeffs = numerical_df.corr()['SalePrice'].abs().sort_values()\n",
    "    df = df.drop(abs_corr_coeffs[abs_corr_coeffs < coeff_threshold].index, axis=1)\n",
    "    \n",
    "    nominal_features = [\"PID\", \"MS SubClass\", \"MS Zoning\", \"Street\", \"Alley\", \"Land Contour\", \"Lot Config\", \"Neighborhood\", \n",
    "                    \"Condition 1\", \"Condition 2\", \"Bldg Type\", \"House Style\", \"Roof Style\", \"Roof Matl\", \"Exterior 1st\", \n",
    "                    \"Exterior 2nd\", \"Mas Vnr Type\", \"Foundation\", \"Heating\", \"Central Air\", \"Garage Type\", \n",
    "                    \"Misc Feature\", \"Sale Type\", \"Sale Condition\"]\n",
    "    \n",
    "    transform_cat_cols = []\n",
    "    for col in nominal_features:\n",
    "        if col in df.columns:\n",
    "            transform_cat_cols.append(col)\n",
    "\n",
    "    uniqueness_counts = df[transform_cat_cols].apply(lambda col: len(col.value_counts())).sort_values()\n",
    "    drop_nonuniq_cols = uniqueness_counts[uniqueness_counts > 10].index\n",
    "    df = df.drop(drop_nonuniq_cols, axis=1)\n",
    "    \n",
    "    text_cols = df.select_dtypes(include=['object'])\n",
    "    for col in text_cols:\n",
    "        df[col] = df[col].astype('category')\n",
    "    df = pd.concat([df, pd.get_dummies(df.select_dtypes(include=['category']))], axis=1).drop(text_cols,axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def train_and_test(df, k=0):\n",
    "    numeric_df = df.select_dtypes(include=['integer', 'float'])\n",
    "    features = numeric_df.columns.drop(\"SalePrice\")\n",
    "    lr = LinearRegression()\n",
    "    \n",
    "    if k == 0:\n",
    "        train = df[:1460]\n",
    "        test = df[1460:]\n",
    "\n",
    "        lr.fit(train[features], train[\"SalePrice\"])\n",
    "        predictions = lr.predict(test[features])\n",
    "        mse = mean_squared_error(test[\"SalePrice\"], predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        return rmse\n",
    "    \n",
    "    if k == 1:\n",
    "        # Randomize *all* rows (frac=1) from `df` and return\n",
    "        shuffled_df = df.sample(frac=1, )\n",
    "        train = df[:1460]\n",
    "        test = df[1460:]\n",
    "        \n",
    "        lr.fit(train[features], train[\"SalePrice\"])\n",
    "        predictions_one = lr.predict(test[features])        \n",
    "        \n",
    "        mse_one = mean_squared_error(test[\"SalePrice\"], predictions_one)\n",
    "        rmse_one = np.sqrt(mse_one)\n",
    "        \n",
    "        lr.fit(test[features], test[\"SalePrice\"])\n",
    "        predictions_two = lr.predict(train[features])        \n",
    "       \n",
    "        mse_two = mean_squared_error(train[\"SalePrice\"], predictions_two)\n",
    "        rmse_two = np.sqrt(mse_two)\n",
    "        \n",
    "        avg_rmse = np.mean([rmse_one, rmse_two])\n",
    "        print(rmse_one)\n",
    "        print(rmse_two)\n",
    "        return avg_rmse\n",
    "    \n",
    "    else:\n",
    "        kf = KFold(n_splits=k, shuffle=True)\n",
    "        rmse_values = []\n",
    "        \n",
    "        for train_index, test_index, in kf.split(df):\n",
    "            train = df.iloc[train_index]\n",
    "            test = df.iloc[test_index]\n",
    "            lr.fit(train[features], train[\"SalePrice\"])\n",
    "            predictions = lr.predict(test[features])\n",
    "            mse = mean_squared_error(test[\"SalePrice\"], predictions)\n",
    "            rmse = np.sqrt(mse)\n",
    "            rmse_values.append(rmse)\n",
    "        print(rmse_values)\n",
    "        avg_rmse = np.mean(rmse_values)\n",
    "            \n",
    "        return avg_rmse\n",
    "        \n",
    "\n",
    "data = pd.read_csv(\"datasets/AmesHousing.tsv\", delimiter=\"\\t\")\n",
    "transform_df = transform_features(data)\n",
    "filtered_df = select_features(transform_df)\n",
    "rmse = train_and_test(filtered_df, k=4)\n",
    "\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "We've explored several methods to achieve more accurate predictions of the Sale Price of houses and was able to halve the RMSE by using KFold cross-validation using 4 folds.  \n",
    "Further optimization could consist of researching on feature selection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
